\newcommand{\rr}{\ensuremath{\mathbb{R}}}

\newpage
\s{1.2}{Random Varibles}
\begin{definition}
    Let (\om, \C{F}) be a measurable space, A function:
    \begin{align*}
        \xi: (\om, \C{F}) & \lr (\rr, \C{B}(\rr))\\
        \omega & \sr \xi(\omega)
    \end{align*} 
    is said to be a \C{F}-measurable if for 
    \begin{align*}
        & \A B\in \C{B}(\rr) \\
        \xi^{-1}  & = \{\omega\in\om, \xi(\omega)\in B\}\\
                  & = \{\xi\in B\}\in\C{F} 
    \end{align*} 
    实际上就是意味着：像空间中的任意元素在 \C{F} 中有一个原象。其实就是为了保证：\newline
    $P(\xi\in B), P(\bigcup_{i=1}^\infty A_i) $等有意义
\end{definition}

In Particular, if $(\om, \C{F}, P)$ is a Probability Space, then a 
\C{F}-measurable function $\xi$ is called Random Varible(short for r.v.)

\remark\\ 
(1) Note that \C{B}(\rr) = $\sigma(\{(-\infty, x]:x\in \rr\})$ \\
we have $\xi$ is a r.v. \equ $\A B \in \C{B}(\rr), \{\xi \in B\}\in\C{F}$\\
\hspace*{8.2em}\equ $\A x \in \rr, \{\xi\le x\}\in\C{F}$(\mbox{后一个等价条件证明过于复杂})\\
(2) if $\{\xi_n\}$ is a sequence of r.v. and $\lim\limits_{n\to\infty}{\xi_n}=\xi$. a.s. then $\xi$ is also a r.v.\\
(3) if $\xi$ is a r.v.  and $g$ is a $\C{B}(\rr)$-measurable function, then $g(s)$ is also a r.v.


\begin{definition} what's the $\sigma$-field generated by a r.v.? It can be defined as follows:
    \begin{align*}
        \sigma(\xi) & = the\ \sigma-field\ generated\ by\ \xi\\
        & = the\ smalllest\ \sigma-field\ generated\ such\ that\ \xi\ is\ measurable\\
        & = the\ intersection\ of\ all\ \sigma-field\ such\ that\ \xi\ is\ measurable\\
        & = \sigma(\{\xi^{-1}(B):B\in \C{B}(\rr)\}) \equ \sigma(\{\{\xi\in B\}:B\in\C{B}(\rr)\})\\
        & = \sigma(\{\xi^{-1}((-\infty, x]):x\in \rr\}) \equ \sigma(\{\{\xi\le x\}:x\in \rr\})\\
        & = \sigma(\{\xi^{-1}((a, b]): a, b\in \rr\}) \equ \sigma(\{\{a<x\le b\}:a, b\in \rr\})
    \end{align*}
\end{definition}


\emp{Example } 

Let $\om = \{\omega_1,\omega_2, \omega_3\}$ be a simple space.
Take $A = \{\omega_1, \omega_2\}, \C{F}_1 = \{\ns, A, A^c, \om\}, \C{F}_2 = 2^\om$. Consider the 
following function on \om:
\begin{align*}
    X(\omega_1) = X(\omega_2) = 0.5 &\qquad X(\omega_3) = 1.5\\
    Y(\omega_1) = 2.25, Y(\omega_4) = 0.25 &\qquad Y(\omega_2) = Y(\omega_3) = 0.7
\end{align*}

\noindent(1) Then we have: $X$ is a r.v. {\color{red}on \C{F}}, but $Y$ is not a r.v. {\color{red} on \C{F}}

\emp{In Fact}

$X^{-1}\{0.5\} = \{\omega: X(\omega) = 0.5\} = \{\omega_1,\omega_2\} = A\in \C{F}$

$X^{-1}\{1.5\} = \{\omega: X(\omega) = 1.5\} = \{\omega_3,\omega_4\} = A^c\in\C{F}$

$X^{-1}\{0.5, 1.5\} = \om \in\C{F}_1$

if $a \neq 0.5, 1.5 $ then $X^{-1}\{a\} = \ns\notin \C{F}$
{\color{red} \lrr} X is a r.v. on $\C{F}_1$

\emp{However}

$Y^{-1}\{2.25\} = \{\omega: Y(\omega) = 2.25\} = \{\omega_1\} \notin\C{F}$\quad (Although $\omega_1 \in A$)\\
{\color{red} \lrr} $Y$ is not a r.v. on $\C{F}_1$

\noindent(2) For $\C{F}_2 = 2^\om$, both $X, Y$ are r.v. on $\C{F}_2$ 

\noindent(3) The specific form of $\sigma(X)$ and $\sigma(Y)$ are as follows:
\begin{align*}
    & \sigma(X) = \sigma(\{\{x\in B\}:B\in \C{B}(\rr)\}) = \{A, A^c, \ns, \om\} = \C{F}_1   \\ 
    & \sigma(Y) = \{\ns, \om, \underbrace{\{\omega_1\}, \{\omega_2, \omega_3, \omega_4\}}, \underbrace{\{\omega_4\}, \{\omega_1, \omega_2, \omega_3\}}, \underbrace{\{\omega_2,\omega_3\},\{\omega_1, \omega_4\}}\} 
\end{align*}

\begin{lemma}
    \F{(Doob-Dynkin)} Let $\xi$ is a r.v. Then each $\sigma(\xi)$-measurable r.v. $\eta$
    can be Written as 
    \begin{align*}
        \eta = f(\xi)
    \end{align*}
    for some $\C{B}(\rr)$-measurable function \im{f:\rr\sr\rr}
\end{lemma}

\begin{definition}
   (1) Let $\xi:\om \lr \rr$ be a r.v. Write:
    \begin{align*}
        P_\xi(B) & = P(\xi\in B) = P\{\omega:\xi(\omega)\in B\}\notag\\
                 & = P\{\omega: \omega\in \xi^{-1}(B)\}\notag\\
                 & = P(\xi^{-1}(B))\notag\\
                 & = P\circ \xi^{-1}(B) 
    \end{align*}

    (2) The function \im{F_s:(\rr)\sr [0, 1]} defined by 
    \begin{align*}
        F_\xi(x) = P_x((-\infty, x]) = P(\xi \le x), \qquad x \in \rr
    \end{align*}
    is called the distribution function of $\xi$
\end{definition}

\remark 
\begin{align}
    \int_{-\infty}^{x}{\mathrm{d F_\xi(\mu)}} = \int_{-\infty}^{x}{\mathrm{P_\xi(\mu)}} = \int_{-\infty}^{x}{\mathrm{dP\circ \xi^{-1}(\mu)}} 
    {\color{red} \lrr \mathrm{dF_\xi(\mu)} = \mathrm{dP\circ\xi^{-1}(\mu) }}\notag
\end{align}


\begin{definition}
    (1) A discreate r.v. $\xi$:
    \begin{align*}
        P(\xi\in B) = \sum_{x_i \in B}^{}{P(\xi = x_i)} 
    \end{align*}
\end{definition}


Total as follows:

\begin{center}
\begin{tabular}{c|cccc}
    $\xi$ & $X_1$ & $X_2$ & $\cdots$ & $X_n$\\
    \hline
    $P$ &  $P(\xi=X_1)$ & $P(\xi = X_2)$ & $\cdots$ & $P(\xi_n = X_n) $ 
\end{tabular}
\end{center}

(2) A continuous r.v. $\xi$:
\begin{align*}
    P(\xi\in B) = \int_{B}^{}{f_B \mathrm{dx}} \lr \mbox{(This is in Form of \im{\mathbf{Lebesgue\ Integrate}})}
\end{align*}
\im{f_\xi} is called the density function of $\xi$


\newcommand{\seqxi}{\ensuremath{\xi_1, \xi_2, \cdots, \xi_n}}
\begin{definition}
(1) $n$ dimensional discreate  r.v. \seqxi.
\im{P_{\xi_1, \cdots, \xi_n}(B) = }\\\im{P\{(\xi_1, \xi_2,\cdots, \xi_n)\in B\}}, We Have:
\begin{align*}
    F_{\xi_1, \cdots,\xi_n}(x_1, x_2, \cdots, x_n) = P_{\xi_1, \cdots,\xi_n}\bigg((-\infty, x_1]\times (-\infty, x_2]\times\cdots\times(-\infty, x_n]\bigg)
\end{align*}

(2) The $\mathrm{n}$-dimensional contains r.v. (\seqxi) :
\begin{align*}
    P\{(\seqxi) \in B\} = \int_{B}^{}{f_{\seqxi}(x_1, x_2,\cdots, x_n) \mathrm{dx_1dx_2\cdots dx_n}} 
    ,\quad B \in \C{B}(\rr)
\end{align*}
\end{definition}

\begin{definition}
    (1) A r.v. $\xi: \rr \sr \rr$ is said to be Integratable if 
    \begin{align*}
        \int_{\om}^{}{|\xi| \mathrm{d}p < +\infty}
    \end{align*}

    (2) The Space $\C{L}^1$ and $\C{L}^2$:
    \begin{align*}
    \C{L}^1 := \C{L}^1(\om, \C{F}, P) = \bigg\{\xi: \int_{\om}^{}{|\xi| {\rm d} p} < +\infty\bigg\}
    \end{align*}

    (3) Let $\xi \in \C{L}^1$, then the \im{\mathbf{Expectation}} of $\xi$ exists and defined by
    \begin{align}
        E(\xi) = \int_{\om}^{}{\xi {\rm d} p} = \int_{\om}^{}{\xi(\omega) p({\rm d}\omega)} 
        = \left\{
        \begin{aligned}
            & \sum_{i}^{}{x_i\cdot P(\xi=x_i)}\\
            & \int_{-\infty}^{+\infty}{x\cdot f_\xi (x){\rm d} x}
        \end{aligned}
        \right.
    \end{align}

    \remark \\
    (1) A r.v. $\xi$ is Integratable \equ \im{E(|\xi|) < +\infty}  \equ \im{\xi \in L^1(\om, \C{F}, p)}\\
    (2)  Let $\xi(\omega) = x$ , that's to say $\omega\in \xi^{-1}(x)$, we have
    \begin{align*}
        E(\xi) = \int_{\om}^{}{\xi(\omega) p({\rm d} \omega)}
        = \int_{-\infty}^{+\infty}{x\cdot {\rm d}P\circ \xi^{-1}(x)
        = \int_{-\infty}^{+\infty}{x\cdot {\rm d} F_\xi(x)}}
    \end{align*}
\end{definition}

\begin{definition}
    \im{\mathbf{(Indicator\ funtion)}} (1) The Indicator function of a set $A$ is :
    \begin{align*}
        \mathbf{1}_A(\omega)
        \left\{
        \begin{aligned}
            & 1, \omega \in A \\
            & 0, \omega \notin A
        \end{aligned}
        \right.
    \end{align*}

    Then $\mathbf{1}_A$ is a r.v. and \im{\mathbf{1}_A \sim b(1, p)}, whose $P = P(A)$.
    The below is :
    \begin{center}
        \begin{tabular}{c|cc}
            $\mathbf{1}_A$ & 0 & $1$\\
            \hline
            $P$ & $1-P(A)$ & $P(A)$
        \end{tabular}
        \quad \im{E(\mathbf{1}_A) = P(A) \qquad\big(\int_{\om}{\mathbf{1}_A {\rm d}p} = \int_{A}^{}{{\rm d} p}\big)}
    \end{center}

    \noindent(3) We say that $\eta:\om \sr \rr$ is a simple function or a step function if:
    \begin{align*}
    \eta (\omega) = \sum_{i=1}^{n}{a_i\cdot\mathbf{1}_A(\omega)}
    \end{align*}
    where $a_1, a_2, \cdots, a_n$ are constants and $A_1, A_2, \cdots, A_n$ are pairwise disjoint events. Then:
    \begin{align*}
        E(\eta) = \sum_{i=1}^{n}{a_i\cdot E(\mathbf{1}_{A_{i}})} = \sum_{i=1}^{n}{a_i\cdot P(A_i)}
    \end{align*}

    \remark If a r.v. $\xi\ge 0$ then \im{E(\xi) = 0 \equ P(\xi = 0) = 1}  
\end{definition}

\newcommand{\D}{\ensuremath{\mathrm{d}}}
Proof the Expectation of a r.v. $\eta^2$:
\begin{align*}
    E(\eta^2)  
    & = \int_{\om}^{}{\eta^2 \D p} = 2 \int_{\om}^{}{\big(\int_{0}^{\eta}{t \D t} \big) \D p} \\
    & = 2 \int_{\om}^{}{\bigl(\int_{0}^{t}{t \cdot \mathbf{1}_{\{\eta > t\}}} \D t\bigr) \D p} \\
    & = 2 \int_{0}^{+\infty}{\bigl(\int_{\om}^{}{\mathbf{1}_{\{\eta > t\}} \D p} \bigr) \D t} \\
    & = 2 \int_{0}^{+\infty}{t\cdot P(\eta > t) \D t}
\end{align*}
